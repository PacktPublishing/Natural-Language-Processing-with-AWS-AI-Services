{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import webbrowser, os\n",
    "import json\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "import uuid\n",
    "import time\n",
    "import io\n",
    "from io import BytesIO\n",
    "import sys\n",
    "import csv\n",
    "from pprint import pprint\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PImage, ImageDraw\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "sess = sagemaker.Session()\n",
    "s3BucketName =  \"workshop-textract-b9e2b520\"\n",
    "prefix = 'chapter5'\n",
    "\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize the boto3 handle for comprehend\n",
    "comprehend = boto3.client('comprehend')\n",
    "textract= boto3.client('textract')\n",
    "kendra= boto3.client('kendra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document\n",
    "documentName = \"resume_Sample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startJob(s3BucketName, objectName):\n",
    "    response = None\n",
    "    response = textract.start_document_text_detection(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': s3BucketName,\n",
    "            'Name': objectName\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return response[\"JobId\"]\n",
    "\n",
    "def isJobComplete(jobId):\n",
    "    response = textract.get_document_text_detection(JobId=jobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    print(\"Job status: {}\".format(status))\n",
    "\n",
    "    while(status == \"IN_PROGRESS\"):\n",
    "        time.sleep(5)\n",
    "        response = textract.get_document_text_detection(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    "        print(\"Job status: {}\".format(status))\n",
    "\n",
    "    return status\n",
    "\n",
    "def getJobResults(jobId):\n",
    "\n",
    "    pages = []\n",
    "    response = textract.get_document_text_detection(JobId=jobId)\n",
    "    \n",
    "    pages.append(response)\n",
    "    print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']\n",
    "\n",
    "    while(nextToken):\n",
    "        response = textract.get_document_text_detection(JobId=jobId, NextToken=nextToken)\n",
    "\n",
    "        pages.append(response)\n",
    "        print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "        nextToken = None\n",
    "        if('NextToken' in response):\n",
    "            nextToken = response['NextToken']\n",
    "\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "jobId = startJob(s3BucketName, documentName)\n",
    "print(\"Started job with id: {}\".format(jobId))\n",
    "if(isJobComplete(jobId)):\n",
    "    response = getJobResults(jobId)\n",
    "\n",
    "#print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detected text\n",
    "text=\"\"\n",
    "for resultPage in response:\n",
    "    for item in resultPage[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            #print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')\n",
    "            text += item['Text']+\"\\n\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-moses",
   "metadata": {},
   "source": [
    "# Call Amazon Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities= comprehend.detect_entities(Text=text, LanguageCode='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(entities, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-delay",
   "metadata": {},
   "source": [
    "# Create Kendra Index \n",
    "Please craete an IAM role and provide in Role ARN, \n",
    "alternatively go to Kendra console to create an index and skip creating using API.\n",
    "https://docs.aws.amazon.com/kendra/latest/dg/deploying.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code only once as it will craete multiple indexes\n",
    "response = kendra.create_index(\n",
    "    Name='Search',\n",
    "    Edition='DEVELOPER_EDITION',\n",
    "    RoleArn='<enter your role arn>')\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-kingston",
   "metadata": {},
   "source": [
    "Get IndexId from Console and paste it in ID or run above code to create Index which will give 36 digit Index ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kendra.update_index(\n",
    "    Id=\"<paste Index Id from Craete Index response>\",\n",
    "    DocumentMetadataConfigurationUpdates=[\n",
    "        {\n",
    "            'Name':'ORGANIZATION',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': True,\n",
    "                'Searchable': True,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name':'PERSON',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': False,\n",
    "                'Searchable': True,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name':'DATE',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': False,\n",
    "                'Searchable': True,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name':'COMMERCIAL_ITEM',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': True,\n",
    "                'Searchable': False,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name':'OTHER',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': True,\n",
    "                'Searchable': True,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        }\n",
    "        ,\n",
    "        {\n",
    "            'Name':'QUANTITY',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': True,\n",
    "                'Searchable': True,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        }\n",
    "        ,\n",
    "        {\n",
    "            'Name':'TITLE',\n",
    "            'Type':'STRING_LIST_VALUE',\n",
    "            'Search': {\n",
    "                'Facetable': False,\n",
    "                'Searchable': True,\n",
    "                'Displayable': True\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of categories recognized by Comprehend \n",
    "categories = [\"ORGANIZATION\", \"PERSON\", \"DATE\", \"COMMERCIAL_ITEM\", \"OTHER\", \"TITLE\", \"QUANTITY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of JSON objects to store entities\n",
    "entity_data = dict()\n",
    "#List of observed text strings recognized as categories\n",
    "category_text = dict()\n",
    "#Frequency of each text string\n",
    "text_frequency = dict()\n",
    "#The Kendra attributes JSON object with metadata list to be populated\n",
    "attributes = dict()\n",
    "metadata = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "for et in categories:\n",
    "        entity_data[et] = set()\n",
    "        #print(entity_data[et])\n",
    "        category_text[et] = []\n",
    "        text_frequency[et] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in entities[\"Entities\"]:\n",
    "    if (e[\"Text\"].isprintable()) and (not \"\\\"\" in e[\"Text\"]) and (not e[\"Text\"].upper() in category_text[e[\"Type\"]]):\n",
    "                #Append the text to entity data to be used for a Kendra custom attribute\n",
    "                entity_data[e[\"Type\"]].add(e[\"Text\"])\n",
    "                #Keep track of text in upper case so that we don't treat the same text written in different cases differently\n",
    "                category_text[e[\"Type\"]].append(e[\"Text\"].upper())\n",
    "                #Keep track of the frequency of the text so that we can take the text with highest frequency of occurrance\n",
    "                text_frequency[e[\"Type\"]][e[\"Text\"].upper()] = 1\n",
    "    elif (e[\"Text\"].upper() in category_text[e[\"Type\"]]):\n",
    "                #Keep track of the frequency of the text so that we can take the text with highest frequency of occurrance\n",
    "                text_frequency[e[\"Type\"]][e[\"Text\"].upper()] += 1\n",
    "\n",
    "print(entity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate the metadata list\n",
    "elimit = 10\n",
    "for et in categories:\n",
    "        #Take at most elimit number of recognized text strings having the highest frequency of occurrance\n",
    "    el = [pair[0] for pair in sorted(text_frequency[et].items(), key=lambda item: item[1], reverse=True)][0:elimit]\n",
    "    metadata[et] = [d for d in entity_data[et] if d.upper() in el]\n",
    "metadata[\"_source_uri\"] = documentName\n",
    "attributes[\"Attributes\"] = metadata\n",
    "print(json.dumps(attributes, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.json\", \"w\") as f:\n",
    "     json.dump(attributes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "prefix= 'meta/'\n",
    "with open(\"metadata.json\", \"rb\") as f:\n",
    "    #s3.upload_fileobj(f,s3BucketName, prefix+\"resume_Sample.pdf.metadata.json\")\n",
    "    s3.upload_file( \"metadata.json\", s3BucketName,'%s/%s' % (\"meta\",\"resume_Sample.pdf.metadata.json\"))\n",
    "print(\"Uploaded to Amazon S3 meta folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-laundry",
   "metadata": {},
   "source": [
    "# Run Kendra Sync in AWS Console"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
